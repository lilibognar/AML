{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"train_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((train_csv['label']).value_counts()).describe())\n",
    "len(train_csv['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING\n",
    "\n",
    "    Resize images (e.g., 224x224).\n",
    "    Normalize pixel values to range [0, 1].\n",
    "    Apply data augmentation (rotation, flipping, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\martj\\AppData\\Local\\Temp\\ipykernel_516\\2724898715.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  img_path = (base_folder + row[0])  # Add base folder to path\n",
      "C:\\Users\\martj\\AppData\\Local\\Temp\\ipykernel_516\\2724898715.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label = row[1]  # Label\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_data(csv_data, base_folder='', img_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess images based on CSV paths and labels.\n",
    "    Args:\n",
    "        csv_data: Pandas DataFrame with 'path' and 'label' columns.\n",
    "        base_folder: Base folder containing the images (e.g., \"train_images\").\n",
    "        img_size: Target size for resizing images.\n",
    "    Returns:\n",
    "        images: Numpy array of image data.\n",
    "        labels: Numpy array of labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in csv_data.iterrows():\n",
    "        img_path = (base_folder + row[0])  # Add base folder to path\n",
    "        label = row[1]  # Label\n",
    "\n",
    "        # Load and preprocess the image\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0  # Normalize\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Preprocess training data\n",
    "train_images, train_labels = preprocess_data(train_csv, base_folder=\"C:/Users/martj/Desktop/Applied ML/AML-assignment/train_images\")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(np.unique(train_labels))\n",
    "\n",
    "# # Adjust labels to 0-based indexing\n",
    "train_labels = train_labels - 1\n",
    "train_labels = to_categorical(train_labels, num_classes=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique one-hot encoded vectors\n",
    "unique_vectors = np.unique(train_labels, axis=0)\n",
    "#print(len(unique_vectors))  # This will give the number of unique vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split into training + validation and test sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
    ")\n",
    "\n",
    "# Next, split the training data into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    train_images, train_labels, test_size=0.25, random_state=42, stratify=train_labels\n",
    ")  # 0.25 x 0.8 = 0.2 of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size 2355\n",
      "test data size 786\n",
      "validation data size 785\n"
     ]
    }
   ],
   "source": [
    "print(\"train data size\", len(train_labels))\n",
    "print(\"test data size\", len(test_labels))\n",
    "print(\"validation data size\", len(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique labels in training data 200\n",
      "unique labels in test data 200\n",
      "unique labels in validation data 200\n"
     ]
    }
   ],
   "source": [
    "# Find unique one-hot encoded vectors\n",
    "unique_vectors = np.unique(train_labels, axis=0)\n",
    "print(\"unique labels in training data\", len(unique_vectors))  # This will give the number of unique vectors\n",
    "# Find unique one-hot encoded vectors\n",
    "unique_vectors = np.unique(test_labels, axis=0)\n",
    "print(\"unique labels in test data\", len(unique_vectors))  # This will give the number of unique vectors\n",
    "# Find unique one-hot encoded vectors\n",
    "unique_vectors = np.unique(val_labels, axis=0)\n",
    "print(\"unique labels in validation data\", len(unique_vectors))  # This will give the number of unique vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define data generators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Can mess with this too, although I did not see much change when doing so \n",
    "train_datagen = ImageDataGenerator(\n",
    "    #Randomly rotates the image within a range of Â±20 degrees\n",
    "    rotation_range=30,\n",
    "    #Shifts the image horizontally by a random fraction (up to 20% of the width)\n",
    "    width_shift_range=0.3,\n",
    "    #Shifts the image vertically by a random fraction (up to 20% of the height)\n",
    "    height_shift_range=0.3,\n",
    "    #Applies a random shearing transformation within 0.2 radians\n",
    "    shear_range=0.2,\n",
    "    #Zooms in or out on the image randomly by up to 20%\n",
    "    zoom_range=0.2,\n",
    "    # Randomly flips the image horizontally\n",
    "    horizontal_flip=True,\n",
    "    #Fills in pixels that are generated due to transformations using the nearest pixel values\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "# Apply data augmentation to training images only\n",
    "train_generator = train_datagen.flow(\n",
    "    train_images, train_labels, batch_size=32\n",
    ")\n",
    "val_datagen = ImageDataGenerator()  # No augmentation for validation\n",
    "val_generator = val_datagen.flow(\n",
    "    val_images, val_labels, batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This is implementation only for MobileNetV2 model ####\n",
    "\n",
    "\n",
    "# from tensorflow.keras.applications import MobileNetV2\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "# # Load Pre-trained Model\n",
    "# # Maybe look for different pretrained models as well\n",
    "# base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "# # Add Custom Layers\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# # First dense layer\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# predictions = Dense(num_classes, activation='softmax')(x)\n",
    "# # Define the Model\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# #Freeze Base Layers for Transfer Learning\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "# # base_model.trainable = True\n",
    "# # for layer in base_model.layers[:-20]:  # Example: Freeze all but the last 20 layers\n",
    "# #     layer.trainable = False\n",
    "# # Compile Model\n",
    "# #smaller learning rate when fine-tuning to avoid destroying pre-trained weights\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Load pretrained MobileNetV2\n",
    "mobile_net = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "mobile_net.trainable = False  # Freeze the base model\n",
    "\n",
    "# Load pretrained EfficientNetB0\n",
    "efficient_net = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "efficient_net.trainable = False  # Freeze the base model\n",
    "\n",
    "# Shared input (a single input for both models)\n",
    "input_layer = tf.keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "# Pass the shared input through both models\n",
    "mobile_net_output = mobile_net(input_layer)\n",
    "mobile_net_output = layers.GlobalAveragePooling2D()(mobile_net_output)\n",
    "\n",
    "efficient_net_output = efficient_net(input_layer)\n",
    "efficient_net_output = layers.GlobalAveragePooling2D()(efficient_net_output)\n",
    "\n",
    "# Combine outputs\n",
    "combined = layers.Concatenate()([mobile_net_output, efficient_net_output])\n",
    "\n",
    "# Add classifier layers\n",
    "#dense_layer = layers.Dense(256, activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2(0.01))(combined)\n",
    "dropout_layer = layers.Dropout(0.6)(combined)\n",
    "output_layer = layers.Dense(200, activation=\"softmax\",kernel_regularizer=tf.keras.regularizers.l2(0.01))(dropout_layer)  # Assume 200 classes\n",
    "\n",
    "# Define the combined model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "efficient_net.trainable = True  # Unfreeze EfficientNetB0\n",
    "for layer in efficient_net.layers[:100]:  # Freeze the first 100 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_images) // 32,\n",
    "    validation_steps=len(val_images) // 32\n",
    ")\n",
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, batch_size=32)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "model.save('bird_species_classifier.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels.shape)  # Should be (number of samples,)\n",
    "print(val_labels.shape)    # Should be (number of samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Load the model from the H5 file\n",
    "model = load_model('bird_species_classifier.h5')\n",
    "# Check the model's architecture or summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST IMAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(\"test_images_path.csv\")\n",
    "test_csv = test_csv.drop(columns=['id'])\n",
    "test_images, test_labels = preprocess_data(test_csv, base_folder=\"C:/Users/martj/Desktop/Applied ML/AML-assignment/test_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((test_csv['label']).value_counts()).describe())\n",
    "len(test_csv['label'].unique())\n",
    "#train_csv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 130s 1s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)\n",
    "has_nan = np.isnan(predictions).any()\n",
    "has_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the predicted class for each sample\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# `predicted_classes` will now contain the class index for each sample\n",
    "print(type(predicted_classes))\n",
    "predicted_classes = predicted_classes +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each class\n",
    "unique_classes, class_counts = np.unique(predicted_classes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the counts for each class\n",
    "for class_label, count in zip(unique_classes, class_counts):\n",
    "    print(f\"Class {class_label}: {count} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Replace the 'label' column\n",
    "test_csv['label'] = predicted_classes\n",
    "\n",
    "# Step 4: Save the updated DataFrame to a new CSV file\n",
    "test_csv.to_csv(\"test_images_path_updated.csv\", index=False)\n",
    "\n",
    "print(\"Updated CSV saved as 'test_images_path_updated.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the function to process the CSV\n",
    "def clean_image_path(csv_input_path, csv_output_path):\n",
    "    \"\"\"\n",
    "    Cleans the `image_path` column in the CSV file by extracting only the image ID.\n",
    "    \n",
    "    Args:\n",
    "    - csv_input_path (str): Path to the input CSV file.\n",
    "    - csv_output_path (str): Path to save the cleaned CSV file.\n",
    "    \"\"\"\n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_input_path)\n",
    "\n",
    "    # Extract the image ID from the `image_path` column\n",
    "    df['image_path'] = df['image_path'].str.extract(r'/(\\d+)\\.jpg')[0]\n",
    "\n",
    "    # Save the cleaned DataFrame\n",
    "    df.to_csv(csv_output_path, index=False)\n",
    "    print(f\"Cleaned CSV saved at: {csv_output_path}\")\n",
    "\n",
    "# Example usage\n",
    "csv_input_path = \"test_images_path_updated.csv\"  # Input CSV path\n",
    "csv_output_path = \"test_images_path_cleaned.csv\"  # Output CSV path\n",
    "clean_image_path(csv_input_path, csv_output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
